{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA notebook - Interaction\n",
    "The below steps show how the final model is validated for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import data_preparation as dp\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "house = pd.read_csv(\"../data/kc_house_data.csv\")\n",
    "\n",
    "house.drop(['id',\n",
    "            'date',\n",
    "            'zipcode', \n",
    "            'lat', \n",
    "            'long', 'sqft_above',\n",
    "            'sqft_living15', \n",
    "            'sqft_lot15'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning before finding interaction\n",
    "house = dp.missing(house)\n",
    "house = dp.cleaning(house)\n",
    "house_num_final = dp.numeric_transform(house)\n",
    "house = dp.categorical_tansformation(house)\n",
    "house_final = dp.concatenation(house_num_final, house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = house_final.drop('price', axis = 1)\n",
    "y = house_final['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:      0.4534361083157941\n",
      "Validation score: 0.45952300008481545\n",
      "X-test score: 0.45641912249708183\n",
      "R2 score: 0.45641912249708183\n",
      "Mean**2 Error 0.7337180230010705\n"
     ]
    }
   ],
   "source": [
    "# selecting sqft_living column only as it has the highest correlation with house price column\n",
    "dp.scores(X_train[['sqft_living']], y_train, X_test[['sqft_living']], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:      0.4848214267770404\n",
      "Validation score: 0.48714093663144115\n",
      "X-test score: 0.484503445512511\n",
      "R2 score: 0.484503445512511\n",
      "Mean**2 Error 0.7145127541661467\n"
     ]
    }
   ],
   "source": [
    "# implementing data with just sqft_living column\n",
    "poly = PolynomialFeatures(2)\n",
    "X_poly_train = poly.fit_transform(X_train[['sqft_living']])\n",
    "X_poly_test = poly.transform(X_test[['sqft_living']])\n",
    "\n",
    "dp.scores(X_poly_train, y_train, X_poly_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:      0.48548684435400985\n",
      "Validation score: 0.4870417343473496\n",
      "X-test score: 0.4857001733102616\n",
      "R2 score: 0.4857001733102616\n",
      "Mean**2 Error 0.7136828998143384\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(3)\n",
    "X_poly_train = poly.fit_transform(X_train[['sqft_living']])\n",
    "X_poly_test = poly.transform(X_test[['sqft_living']])\n",
    "\n",
    "dp.scores(X_poly_train, y_train, X_poly_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:      0.6554961568004584\n",
      "Validation score: 0.6562382822720109\n",
      "X-test score: 0.637612306512999\n",
      "R2 score: 0.637612306512999\n",
      "Mean**2 Error 0.59907862233999\n"
     ]
    }
   ],
   "source": [
    "# Scores with all columns\n",
    "# The scores are much higher than the scores from the previous steps\n",
    "# higher mean squared error\n",
    "dp.scores(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.656</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.655</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1713.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 May 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:57:15</td>     <th>  Log-Likelihood:    </th> <td> -14370.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 16197</td>      <th>  AIC:               </th> <td>2.878e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 16178</td>      <th>  BIC:               </th> <td>2.892e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>    0.9537</td> <td>    0.024</td> <td>   40.235</td> <td> 0.000</td> <td>    0.907</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms</th>            <td>   -0.0747</td> <td>    0.006</td> <td>  -11.783</td> <td> 0.000</td> <td>   -0.087</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms</th>           <td>    0.0789</td> <td>    0.009</td> <td>    9.135</td> <td> 0.000</td> <td>    0.062</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living</th>         <td>    0.3492</td> <td>    0.011</td> <td>   32.585</td> <td> 0.000</td> <td>    0.328</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>            <td>   -0.0641</td> <td>    0.006</td> <td>  -11.071</td> <td> 0.000</td> <td>   -0.075</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors</th>              <td>    0.0670</td> <td>    0.007</td> <td>    9.778</td> <td> 0.000</td> <td>    0.054</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>            <td>   -0.3067</td> <td>    0.007</td> <td>  -45.943</td> <td> 0.000</td> <td>   -0.320</td> <td>   -0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th>          <td>    0.9412</td> <td>    0.058</td> <td>   16.167</td> <td> 0.000</td> <td>    0.827</td> <td>    1.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view</th>                <td>    0.2408</td> <td>    0.017</td> <td>   13.977</td> <td> 0.000</td> <td>    0.207</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_renovated</th>        <td>    0.0366</td> <td>    0.027</td> <td>    1.350</td> <td> 0.177</td> <td>   -0.017</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_basement</th>        <td>    0.0931</td> <td>    0.012</td> <td>    7.927</td> <td> 0.000</td> <td>    0.070</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_Fair</th>      <td>   -0.3068</td> <td>    0.050</td> <td>   -6.196</td> <td> 0.000</td> <td>   -0.404</td> <td>   -0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_Good</th>      <td>    0.0380</td> <td>    0.012</td> <td>    3.256</td> <td> 0.001</td> <td>    0.015</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_Very Good</th> <td>    0.1620</td> <td>    0.019</td> <td>    8.686</td> <td> 0.000</td> <td>    0.125</td> <td>    0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_11 Excellent</th>  <td>    0.5412</td> <td>    0.037</td> <td>   14.640</td> <td> 0.000</td> <td>    0.469</td> <td>    0.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_6 Low Average</th> <td>   -1.7971</td> <td>    0.033</td> <td>  -54.829</td> <td> 0.000</td> <td>   -1.861</td> <td>   -1.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_7 Average</th>     <td>   -1.3356</td> <td>    0.026</td> <td>  -51.154</td> <td> 0.000</td> <td>   -1.387</td> <td>   -1.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_8 Good</th>        <td>   -0.9140</td> <td>    0.024</td> <td>  -38.188</td> <td> 0.000</td> <td>   -0.961</td> <td>   -0.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_9 Better</th>      <td>   -0.3973</td> <td>    0.025</td> <td>  -16.194</td> <td> 0.000</td> <td>   -0.445</td> <td>   -0.349</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>41.176</td> <th>  Durbin-Watson:     </th> <td>   2.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  51.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.034</td> <th>  Prob(JB):          </th> <td>7.46e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.267</td> <th>  Cond. No.          </th> <td>    21.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.656\n",
       "Model:                            OLS   Adj. R-squared:                  0.655\n",
       "Method:                 Least Squares   F-statistic:                     1713.\n",
       "Date:                Sun, 08 May 2022   Prob (F-statistic):               0.00\n",
       "Time:                        11:57:15   Log-Likelihood:                -14370.\n",
       "No. Observations:               16197   AIC:                         2.878e+04\n",
       "Df Residuals:                   16178   BIC:                         2.892e+04\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                   0.9537      0.024     40.235      0.000       0.907       1.000\n",
       "bedrooms               -0.0747      0.006    -11.783      0.000      -0.087      -0.062\n",
       "bathrooms               0.0789      0.009      9.135      0.000       0.062       0.096\n",
       "sqft_living             0.3492      0.011     32.585      0.000       0.328       0.370\n",
       "sqft_lot               -0.0641      0.006    -11.071      0.000      -0.075      -0.053\n",
       "floors                  0.0670      0.007      9.778      0.000       0.054       0.080\n",
       "yr_built               -0.3067      0.007    -45.943      0.000      -0.320      -0.294\n",
       "waterfront              0.9412      0.058     16.167      0.000       0.827       1.055\n",
       "view                    0.2408      0.017     13.977      0.000       0.207       0.275\n",
       "is_renovated            0.0366      0.027      1.350      0.177      -0.017       0.090\n",
       "has_basement            0.0931      0.012      7.927      0.000       0.070       0.116\n",
       "condition_Fair         -0.3068      0.050     -6.196      0.000      -0.404      -0.210\n",
       "condition_Good          0.0380      0.012      3.256      0.001       0.015       0.061\n",
       "condition_Very Good     0.1620      0.019      8.686      0.000       0.125       0.199\n",
       "grade_11 Excellent      0.5412      0.037     14.640      0.000       0.469       0.614\n",
       "grade_6 Low Average    -1.7971      0.033    -54.829      0.000      -1.861      -1.733\n",
       "grade_7 Average        -1.3356      0.026    -51.154      0.000      -1.387      -1.284\n",
       "grade_8 Good           -0.9140      0.024    -38.188      0.000      -0.961      -0.867\n",
       "grade_9 Better         -0.3973      0.025    -16.194      0.000      -0.445      -0.349\n",
       "==============================================================================\n",
       "Omnibus:                       41.176   Durbin-Watson:                   2.005\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.243\n",
       "Skew:                          -0.034   Prob(JB):                     7.46e-12\n",
       "Kurtosis:                       3.267   Cond. No.                         21.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condition number is a bit higher. It means there is some multicollinearity.\n",
    "sm.OLS(y_train, sm.add_constant(X_train)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:      0.5003532396509703\n",
      "Validation score: 0.5042691681991028\n",
      "X-test score: 0.5019864253772119\n",
      "R2 score: 0.5019864253772119\n",
      "Mean**2 Error 0.7022919532225378\n"
     ]
    }
   ],
   "source": [
    "# Scores with 5 columns with only numerical columns\n",
    "# Scores are lowered while mean squared error is higher\n",
    "var = ['sqft_living', 'bathrooms', 'bedrooms', 'floors', 'view']\n",
    "\n",
    "dp.scores(X_train[var], y_train, X_test[var], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:      0.6515747022621045\n",
      "Validation score: 0.6513176974301091\n",
      "X-test score: 0.6346523693995985\n",
      "R2 score: 0.6346523693995985\n",
      "Mean**2 Error 0.6015202461894136\n"
     ]
    }
   ],
   "source": [
    "# Information on bathrooms and bedrooms are removed for below cells\n",
    "X_train = X_train.drop(['bathrooms','bedrooms'],axis = 1).copy()\n",
    "X_test = X_test.drop(['bathrooms','bedrooms'],axis = 1).copy()\n",
    "\n",
    "dp.scores(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.652</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.651</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1892.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 May 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:57:15</td>     <th>  Log-Likelihood:    </th> <td> -14468.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 16197</td>      <th>  AIC:               </th> <td>2.897e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 16180</td>      <th>  BIC:               </th> <td>2.910e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>    0.9790</td> <td>    0.024</td> <td>   41.423</td> <td> 0.000</td> <td>    0.933</td> <td>    1.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living</th>         <td>    0.3301</td> <td>    0.008</td> <td>   39.854</td> <td> 0.000</td> <td>    0.314</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>            <td>   -0.0659</td> <td>    0.006</td> <td>  -11.384</td> <td> 0.000</td> <td>   -0.077</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors</th>              <td>    0.0817</td> <td>    0.007</td> <td>   12.101</td> <td> 0.000</td> <td>    0.068</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>            <td>   -0.2838</td> <td>    0.006</td> <td>  -45.379</td> <td> 0.000</td> <td>   -0.296</td> <td>   -0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th>          <td>    0.9704</td> <td>    0.059</td> <td>   16.586</td> <td> 0.000</td> <td>    0.856</td> <td>    1.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view</th>                <td>    0.2549</td> <td>    0.017</td> <td>   14.736</td> <td> 0.000</td> <td>    0.221</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_renovated</th>        <td>    0.0743</td> <td>    0.027</td> <td>    2.750</td> <td> 0.006</td> <td>    0.021</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_basement</th>        <td>    0.1176</td> <td>    0.012</td> <td>   10.096</td> <td> 0.000</td> <td>    0.095</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_Fair</th>      <td>   -0.3046</td> <td>    0.050</td> <td>   -6.115</td> <td> 0.000</td> <td>   -0.402</td> <td>   -0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_Good</th>      <td>    0.0370</td> <td>    0.012</td> <td>    3.157</td> <td> 0.002</td> <td>    0.014</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_Very Good</th> <td>    0.1757</td> <td>    0.019</td> <td>    9.425</td> <td> 0.000</td> <td>    0.139</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_11 Excellent</th>  <td>    0.5584</td> <td>    0.037</td> <td>   15.025</td> <td> 0.000</td> <td>    0.486</td> <td>    0.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_6 Low Average</th> <td>   -1.8577</td> <td>    0.033</td> <td>  -56.868</td> <td> 0.000</td> <td>   -1.922</td> <td>   -1.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_7 Average</th>     <td>   -1.3887</td> <td>    0.026</td> <td>  -53.673</td> <td> 0.000</td> <td>   -1.439</td> <td>   -1.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_8 Good</th>        <td>   -0.9414</td> <td>    0.024</td> <td>  -39.428</td> <td> 0.000</td> <td>   -0.988</td> <td>   -0.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_9 Better</th>      <td>   -0.4180</td> <td>    0.025</td> <td>  -16.973</td> <td> 0.000</td> <td>   -0.466</td> <td>   -0.370</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>38.697</td> <th>  Durbin-Watson:     </th> <td>   2.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  47.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.034</td> <th>  Prob(JB):          </th> <td>4.30e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.257</td> <th>  Cond. No.          </th> <td>    17.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.652\n",
       "Model:                            OLS   Adj. R-squared:                  0.651\n",
       "Method:                 Least Squares   F-statistic:                     1892.\n",
       "Date:                Sun, 08 May 2022   Prob (F-statistic):               0.00\n",
       "Time:                        11:57:15   Log-Likelihood:                -14468.\n",
       "No. Observations:               16197   AIC:                         2.897e+04\n",
       "Df Residuals:                   16180   BIC:                         2.910e+04\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                   0.9790      0.024     41.423      0.000       0.933       1.025\n",
       "sqft_living             0.3301      0.008     39.854      0.000       0.314       0.346\n",
       "sqft_lot               -0.0659      0.006    -11.384      0.000      -0.077      -0.055\n",
       "floors                  0.0817      0.007     12.101      0.000       0.068       0.095\n",
       "yr_built               -0.2838      0.006    -45.379      0.000      -0.296      -0.272\n",
       "waterfront              0.9704      0.059     16.586      0.000       0.856       1.085\n",
       "view                    0.2549      0.017     14.736      0.000       0.221       0.289\n",
       "is_renovated            0.0743      0.027      2.750      0.006       0.021       0.127\n",
       "has_basement            0.1176      0.012     10.096      0.000       0.095       0.140\n",
       "condition_Fair         -0.3046      0.050     -6.115      0.000      -0.402      -0.207\n",
       "condition_Good          0.0370      0.012      3.157      0.002       0.014       0.060\n",
       "condition_Very Good     0.1757      0.019      9.425      0.000       0.139       0.212\n",
       "grade_11 Excellent      0.5584      0.037     15.025      0.000       0.486       0.631\n",
       "grade_6 Low Average    -1.8577      0.033    -56.868      0.000      -1.922      -1.794\n",
       "grade_7 Average        -1.3887      0.026    -53.673      0.000      -1.439      -1.338\n",
       "grade_8 Good           -0.9414      0.024    -39.428      0.000      -0.988      -0.895\n",
       "grade_9 Better         -0.4180      0.025    -16.973      0.000      -0.466      -0.370\n",
       "==============================================================================\n",
       "Omnibus:                       38.697   Durbin-Watson:                   2.007\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               47.738\n",
       "Skew:                          -0.034   Prob(JB):                     4.30e-11\n",
       "Kurtosis:                       3.257   Cond. No.                         17.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condition number is better after removing two columns.\n",
    "# Validation score is slightly lowered, but the impact is very minor.\n",
    "sm.OLS(y_train, sm.add_constant(X_train)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:      0.6756152843579682\n",
      "Validation score: 0.668807038828558\n",
      "X-test score: 0.6555229266242255\n",
      "R2 score: 0.6555229266242255\n",
      "Mean**2 Error 0.5840866276161898\n"
     ]
    }
   ],
   "source": [
    "# Polynomial methos will not be used in this analysis as condition number is very high.\n",
    "poly = PolynomialFeatures(2)\n",
    "X_poly_train = poly.fit_transform(X_train)\n",
    "X_poly_test = poly.transform(X_test)\n",
    "\n",
    "dp.scores(X_poly_train, y_train, X_poly_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.675</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.672</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   264.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 May 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:57:16</td>     <th>  Log-Likelihood:    </th> <td> -13907.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 16197</td>      <th>  AIC:               </th> <td>2.807e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 16070</td>      <th>  BIC:               </th> <td>2.905e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   126</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.6685</td> <td>    0.073</td> <td>    9.181</td> <td> 0.000</td> <td>    0.526</td> <td>    0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.5885</td> <td>    0.049</td> <td>   12.125</td> <td> 0.000</td> <td>    0.493</td> <td>    0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.2336</td> <td>    0.026</td> <td>   -8.931</td> <td> 0.000</td> <td>   -0.285</td> <td>   -0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1739</td> <td>    0.036</td> <td>   -4.856</td> <td> 0.000</td> <td>   -0.244</td> <td>   -0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.2922</td> <td>    0.039</td> <td>   -7.474</td> <td> 0.000</td> <td>   -0.369</td> <td>   -0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.9019</td> <td>    0.348</td> <td>    2.592</td> <td> 0.010</td> <td>    0.220</td> <td>    1.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.1081</td> <td>    0.035</td> <td>    3.076</td> <td> 0.002</td> <td>    0.039</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2198</td> <td>    0.066</td> <td>    3.307</td> <td> 0.001</td> <td>    0.090</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0078</td> <td>    0.029</td> <td>   -0.270</td> <td> 0.787</td> <td>   -0.064</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.1279</td> <td>    0.306</td> <td>    0.418</td> <td> 0.676</td> <td>   -0.471</td> <td>    0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0384</td> <td>    0.034</td> <td>    1.125</td> <td> 0.261</td> <td>   -0.028</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1980</td> <td>    0.056</td> <td>    3.518</td> <td> 0.000</td> <td>    0.088</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0899</td> <td>    0.072</td> <td>    1.241</td> <td> 0.215</td> <td>   -0.052</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.8298</td> <td>    0.043</td> <td>  -19.264</td> <td> 0.000</td> <td>   -0.914</td> <td>   -0.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.6041</td> <td>    0.037</td> <td>  -16.135</td> <td> 0.000</td> <td>   -0.677</td> <td>   -0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.3942</td> <td>    0.037</td> <td>  -10.685</td> <td> 0.000</td> <td>   -0.467</td> <td>   -0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.1707</td> <td>    0.039</td> <td>   -4.374</td> <td> 0.000</td> <td>   -0.247</td> <td>   -0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0425</td> <td>    0.010</td> <td>    4.224</td> <td> 0.000</td> <td>    0.023</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.0272</td> <td>    0.010</td> <td>   -2.599</td> <td> 0.009</td> <td>   -0.048</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.0182</td> <td>    0.013</td> <td>   -1.359</td> <td> 0.174</td> <td>   -0.045</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0271</td> <td>    0.011</td> <td>    2.358</td> <td> 0.018</td> <td>    0.005</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.3334</td> <td>    0.107</td> <td>    3.123</td> <td> 0.002</td> <td>    0.124</td> <td>    0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0434</td> <td>    0.032</td> <td>   -1.376</td> <td> 0.169</td> <td>   -0.105</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.0991</td> <td>    0.046</td> <td>    2.131</td> <td> 0.033</td> <td>    0.008</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.0534</td> <td>    0.022</td> <td>   -2.386</td> <td> 0.017</td> <td>   -0.097</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.2253</td> <td>    0.081</td> <td>    2.768</td> <td> 0.006</td> <td>    0.066</td> <td>    0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.0191</td> <td>    0.022</td> <td>    0.875</td> <td> 0.381</td> <td>   -0.024</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.1011</td> <td>    0.035</td> <td>    2.902</td> <td> 0.004</td> <td>    0.033</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.0020</td> <td>    0.076</td> <td>    0.026</td> <td> 0.979</td> <td>   -0.146</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -0.2560</td> <td>    0.066</td> <td>   -3.904</td> <td> 0.000</td> <td>   -0.385</td> <td>   -0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -0.2132</td> <td>    0.052</td> <td>   -4.082</td> <td> 0.000</td> <td>   -0.316</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.1933</td> <td>    0.049</td> <td>   -3.965</td> <td> 0.000</td> <td>   -0.289</td> <td>   -0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.0799</td> <td>    0.051</td> <td>   -1.576</td> <td> 0.115</td> <td>   -0.179</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>    0.0423</td> <td>    0.004</td> <td>   11.059</td> <td> 0.000</td> <td>    0.035</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0018</td> <td>    0.008</td> <td>    0.218</td> <td> 0.827</td> <td>   -0.015</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.0639</td> <td>    0.009</td> <td>    6.886</td> <td> 0.000</td> <td>    0.046</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.0571</td> <td>    0.074</td> <td>   -0.772</td> <td> 0.440</td> <td>   -0.202</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.0270</td> <td>    0.018</td> <td>   -1.495</td> <td> 0.135</td> <td>   -0.062</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>    0.0135</td> <td>    0.034</td> <td>    0.400</td> <td> 0.689</td> <td>   -0.053</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   -0.0213</td> <td>    0.015</td> <td>   -1.463</td> <td> 0.143</td> <td>   -0.050</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.0190</td> <td>    0.051</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.082</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    0.0260</td> <td>    0.016</td> <td>    1.661</td> <td> 0.097</td> <td>   -0.005</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -0.0298</td> <td>    0.027</td> <td>   -1.091</td> <td> 0.275</td> <td>   -0.083</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>    0.0010</td> <td>    0.039</td> <td>    0.026</td> <td> 0.979</td> <td>   -0.075</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>    0.1556</td> <td>    0.039</td> <td>    3.989</td> <td> 0.000</td> <td>    0.079</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>    0.1520</td> <td>    0.028</td> <td>    5.479</td> <td> 0.000</td> <td>    0.098</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.1373</td> <td>    0.025</td> <td>    5.502</td> <td> 0.000</td> <td>    0.088</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    0.0412</td> <td>    0.025</td> <td>    1.667</td> <td> 0.096</td> <td>   -0.007</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    0.0637</td> <td>    0.010</td> <td>    6.288</td> <td> 0.000</td> <td>    0.044</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    0.0427</td> <td>    0.010</td> <td>    4.271</td> <td> 0.000</td> <td>    0.023</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    0.0230</td> <td>    0.076</td> <td>    0.301</td> <td> 0.763</td> <td>   -0.127</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>    0.0021</td> <td>    0.022</td> <td>    0.097</td> <td> 0.923</td> <td>   -0.041</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -0.0766</td> <td>    0.037</td> <td>   -2.088</td> <td> 0.037</td> <td>   -0.148</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>    0.0680</td> <td>    0.018</td> <td>    3.806</td> <td> 0.000</td> <td>    0.033</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.0135</td> <td>    0.098</td> <td>   -0.138</td> <td> 0.890</td> <td>   -0.205</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>    0.0335</td> <td>    0.017</td> <td>    1.934</td> <td> 0.053</td> <td>   -0.000</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>    0.0161</td> <td>    0.029</td> <td>    0.550</td> <td> 0.582</td> <td>   -0.041</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>    0.0422</td> <td>    0.057</td> <td>    0.739</td> <td> 0.460</td> <td>   -0.070</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>    0.2166</td> <td>    0.052</td> <td>    4.193</td> <td> 0.000</td> <td>    0.115</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>    0.1980</td> <td>    0.038</td> <td>    5.237</td> <td> 0.000</td> <td>    0.124</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>    0.1454</td> <td>    0.035</td> <td>    4.132</td> <td> 0.000</td> <td>    0.076</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>   <td>    0.0770</td> <td>    0.037</td> <td>    2.086</td> <td> 0.037</td> <td>    0.005</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>   <td>    0.0361</td> <td>    0.007</td> <td>    4.933</td> <td> 0.000</td> <td>    0.022</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>   <td>   -0.1286</td> <td>    0.095</td> <td>   -1.347</td> <td> 0.178</td> <td>   -0.316</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>   <td>   -0.0116</td> <td>    0.023</td> <td>   -0.502</td> <td> 0.616</td> <td>   -0.057</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>   <td>    0.1940</td> <td>    0.039</td> <td>    4.939</td> <td> 0.000</td> <td>    0.117</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>   <td>    0.0352</td> <td>    0.015</td> <td>    2.278</td> <td> 0.023</td> <td>    0.005</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>   <td>   -0.0920</td> <td>    0.078</td> <td>   -1.174</td> <td> 0.240</td> <td>   -0.246</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>   <td>   -0.0820</td> <td>    0.017</td> <td>   -4.869</td> <td> 0.000</td> <td>   -0.115</td> <td>   -0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>   <td>    0.0612</td> <td>    0.027</td> <td>    2.248</td> <td> 0.025</td> <td>    0.008</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>   <td>    0.1649</td> <td>    0.068</td> <td>    2.441</td> <td> 0.015</td> <td>    0.032</td> <td>    0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>   <td>    0.2276</td> <td>    0.049</td> <td>    4.648</td> <td> 0.000</td> <td>    0.132</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>   <td>    0.0238</td> <td>    0.041</td> <td>    0.586</td> <td> 0.558</td> <td>   -0.056</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>   <td>    0.0397</td> <td>    0.039</td> <td>    1.023</td> <td> 0.306</td> <td>   -0.036</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>   <td>    0.0147</td> <td>    0.041</td> <td>    0.361</td> <td> 0.718</td> <td>   -0.065</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>   <td>    0.9019</td> <td>    0.348</td> <td>    2.592</td> <td> 0.010</td> <td>    0.220</td> <td>    1.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>   <td>   -0.6408</td> <td>    0.616</td> <td>   -1.040</td> <td> 0.298</td> <td>   -1.849</td> <td>    0.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>   <td>   -0.5734</td> <td>    0.172</td> <td>   -3.335</td> <td> 0.001</td> <td>   -0.910</td> <td>   -0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>   <td>   -0.3475</td> <td>    0.153</td> <td>   -2.276</td> <td> 0.023</td> <td>   -0.647</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>   <td>   -1.7472</td> <td>    0.924</td> <td>   -1.892</td> <td> 0.059</td> <td>   -3.557</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>   <td>    0.0060</td> <td>    0.145</td> <td>    0.041</td> <td> 0.967</td> <td>   -0.278</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>   <td>   -0.2569</td> <td>    0.199</td> <td>   -1.288</td> <td> 0.198</td> <td>   -0.648</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>   <td>   -0.8789</td> <td>    0.214</td> <td>   -4.113</td> <td> 0.000</td> <td>   -1.298</td> <td>   -0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>   <td>    0.2415</td> <td>    0.407</td> <td>    0.594</td> <td> 0.553</td> <td>   -0.556</td> <td>    1.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>   <td>    0.0584</td> <td>    0.260</td> <td>    0.225</td> <td> 0.822</td> <td>   -0.450</td> <td>    0.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>   <td>    0.0673</td> <td>    0.208</td> <td>    0.324</td> <td> 0.746</td> <td>   -0.340</td> <td>    0.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>   <td>   -0.1320</td> <td>    0.225</td> <td>   -0.585</td> <td> 0.558</td> <td>   -0.574</td> <td>    0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>   <td>    0.1081</td> <td>    0.035</td> <td>    3.076</td> <td> 0.002</td> <td>    0.039</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>   <td>    0.0388</td> <td>    0.079</td> <td>    0.489</td> <td> 0.625</td> <td>   -0.117</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>   <td>    0.0132</td> <td>    0.043</td> <td>    0.309</td> <td> 0.757</td> <td>   -0.071</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>   <td>    0.1017</td> <td>    0.309</td> <td>    0.329</td> <td> 0.742</td> <td>   -0.505</td> <td>    0.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>   <td>    0.0490</td> <td>    0.041</td> <td>    1.183</td> <td> 0.237</td> <td>   -0.032</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>   <td>   -0.0031</td> <td>    0.063</td> <td>   -0.049</td> <td> 0.961</td> <td>   -0.126</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>   <td>    0.0913</td> <td>    0.089</td> <td>    1.023</td> <td> 0.306</td> <td>   -0.084</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>   <td>    0.1257</td> <td>    0.132</td> <td>    0.952</td> <td> 0.341</td> <td>   -0.133</td> <td>    0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>   <td>   -0.0403</td> <td>    0.082</td> <td>   -0.489</td> <td> 0.625</td> <td>   -0.202</td> <td>    0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>   <td>    0.0754</td> <td>    0.069</td> <td>    1.090</td> <td> 0.276</td> <td>   -0.060</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>   <td>   -0.0559</td> <td>    0.067</td> <td>   -0.839</td> <td> 0.402</td> <td>   -0.186</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>   <td>    0.2198</td> <td>    0.066</td> <td>    3.307</td> <td> 0.001</td> <td>    0.090</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>   <td>    0.0036</td> <td>    0.068</td> <td>    0.053</td> <td> 0.958</td> <td>   -0.131</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th>  <td>   -0.9623</td> <td>    0.379</td> <td>   -2.536</td> <td> 0.011</td> <td>   -1.706</td> <td>   -0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th>  <td>   -0.1348</td> <td>    0.076</td> <td>   -1.765</td> <td> 0.078</td> <td>   -0.284</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th>  <td>   -0.3318</td> <td>    0.129</td> <td>   -2.574</td> <td> 0.010</td> <td>   -0.584</td> <td>   -0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th>  <td>   -0.0362</td> <td>    0.211</td> <td>   -0.172</td> <td> 0.864</td> <td>   -0.450</td> <td>    0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th>  <td>   -0.1154</td> <td>    0.172</td> <td>   -0.673</td> <td> 0.501</td> <td>   -0.452</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th>  <td>   -0.1771</td> <td>    0.140</td> <td>   -1.263</td> <td> 0.207</td> <td>   -0.452</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th>  <td>   -0.0104</td> <td>    0.132</td> <td>   -0.079</td> <td> 0.937</td> <td>   -0.268</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th>  <td>   -0.0593</td> <td>    0.137</td> <td>   -0.434</td> <td> 0.664</td> <td>   -0.327</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th>  <td>   -0.0078</td> <td>    0.029</td> <td>   -0.270</td> <td> 0.787</td> <td>   -0.064</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th>  <td>    0.0695</td> <td>    0.137</td> <td>    0.508</td> <td> 0.611</td> <td>   -0.199</td> <td>    0.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th>  <td>    0.0129</td> <td>    0.030</td> <td>    0.431</td> <td> 0.667</td> <td>   -0.046</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th>  <td>   -0.0357</td> <td>    0.049</td> <td>   -0.734</td> <td> 0.463</td> <td>   -0.131</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th>  <td>    0.1452</td> <td>    0.091</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.033</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th>  <td>    0.2281</td> <td>    0.082</td> <td>    2.794</td> <td> 0.005</td> <td>    0.068</td> <td>    0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x114</th>  <td>    0.1312</td> <td>    0.064</td> <td>    2.062</td> <td> 0.039</td> <td>    0.006</td> <td>    0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x115</th>  <td>    0.0770</td> <td>    0.058</td> <td>    1.323</td> <td> 0.186</td> <td>   -0.037</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x116</th>  <td>    0.0500</td> <td>    0.060</td> <td>    0.839</td> <td> 0.401</td> <td>   -0.067</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x117</th>  <td>    0.1279</td> <td>    0.306</td> <td>    0.418</td> <td> 0.676</td> <td>   -0.471</td> <td>    0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x118</th>  <td>-5.964e-16</td> <td>    5e-16</td> <td>   -1.192</td> <td> 0.233</td> <td>-1.58e-15</td> <td> 3.84e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x119</th>  <td>-5.307e-16</td> <td> 3.08e-16</td> <td>   -1.720</td> <td> 0.085</td> <td>-1.14e-15</td> <td> 7.39e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x120</th>  <td>-1.768e-16</td> <td> 2.28e-16</td> <td>   -0.777</td> <td> 0.437</td> <td>-6.23e-16</td> <td> 2.69e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x121</th>  <td>   -0.3760</td> <td>    0.640</td> <td>   -0.588</td> <td> 0.557</td> <td>   -1.630</td> <td>    0.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x122</th>  <td>   -0.4990</td> <td>    0.618</td> <td>   -0.807</td> <td> 0.419</td> <td>   -1.710</td> <td>    0.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x123</th>  <td>   -0.7557</td> <td>    0.627</td> <td>   -1.205</td> <td> 0.228</td> <td>   -1.985</td> <td>    0.474</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x124</th>  <td>   -0.9930</td> <td>    0.763</td> <td>   -1.301</td> <td> 0.193</td> <td>   -2.489</td> <td>    0.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x125</th>  <td>    0.0384</td> <td>    0.034</td> <td>    1.125</td> <td> 0.261</td> <td>   -0.028</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x126</th>  <td>-4.394e-17</td> <td> 1.16e-16</td> <td>   -0.377</td> <td> 0.706</td> <td>-2.72e-16</td> <td> 1.84e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x127</th>  <td>    0.1371</td> <td>    0.116</td> <td>    1.184</td> <td> 0.236</td> <td>   -0.090</td> <td>    0.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x128</th>  <td>    0.0037</td> <td>    0.086</td> <td>    0.043</td> <td> 0.966</td> <td>   -0.166</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x129</th>  <td>   -0.0659</td> <td>    0.074</td> <td>   -0.890</td> <td> 0.374</td> <td>   -0.211</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x130</th>  <td>   -0.0422</td> <td>    0.070</td> <td>   -0.603</td> <td> 0.547</td> <td>   -0.179</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x131</th>  <td>    0.0812</td> <td>    0.075</td> <td>    1.080</td> <td> 0.280</td> <td>   -0.066</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x132</th>  <td>    0.1980</td> <td>    0.056</td> <td>    3.518</td> <td> 0.000</td> <td>    0.088</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x133</th>  <td>    0.0593</td> <td>    0.226</td> <td>    0.262</td> <td> 0.793</td> <td>   -0.384</td> <td>    0.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x134</th>  <td>   -0.0794</td> <td>    0.139</td> <td>   -0.570</td> <td> 0.569</td> <td>   -0.353</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x135</th>  <td>   -0.1359</td> <td>    0.121</td> <td>   -1.127</td> <td> 0.260</td> <td>   -0.372</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x136</th>  <td>   -0.0516</td> <td>    0.114</td> <td>   -0.453</td> <td> 0.651</td> <td>   -0.275</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x137</th>  <td>   -0.0998</td> <td>    0.125</td> <td>   -0.799</td> <td> 0.425</td> <td>   -0.345</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x138</th>  <td>    0.0899</td> <td>    0.072</td> <td>    1.241</td> <td> 0.215</td> <td>   -0.052</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x139</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x140</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x141</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x142</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x143</th>  <td>   -0.8298</td> <td>    0.043</td> <td>  -19.264</td> <td> 0.000</td> <td>   -0.914</td> <td>   -0.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x144</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x145</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x146</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x147</th>  <td>   -0.6041</td> <td>    0.037</td> <td>  -16.135</td> <td> 0.000</td> <td>   -0.677</td> <td>   -0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x148</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x149</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x150</th>  <td>   -0.3942</td> <td>    0.037</td> <td>  -10.685</td> <td> 0.000</td> <td>   -0.467</td> <td>   -0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x151</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x152</th>  <td>   -0.1707</td> <td>    0.039</td> <td>   -4.374</td> <td> 0.000</td> <td>   -0.247</td> <td>   -0.094</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>63.180</td> <th>  Durbin-Watson:     </th> <td>   2.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  83.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.044</td> <th>  Prob(JB):          </th> <td>8.15e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.340</td> <th>  Cond. No.          </th> <td>1.29e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 9.71e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.675\n",
       "Model:                            OLS   Adj. R-squared:                  0.672\n",
       "Method:                 Least Squares   F-statistic:                     264.8\n",
       "Date:                Sun, 08 May 2022   Prob (F-statistic):               0.00\n",
       "Time:                        11:57:16   Log-Likelihood:                -13907.\n",
       "No. Observations:               16197   AIC:                         2.807e+04\n",
       "Df Residuals:                   16070   BIC:                         2.905e+04\n",
       "Df Model:                         126                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.6685      0.073      9.181      0.000       0.526       0.811\n",
       "x1             0.5885      0.049     12.125      0.000       0.493       0.684\n",
       "x2            -0.2336      0.026     -8.931      0.000      -0.285      -0.182\n",
       "x3            -0.1739      0.036     -4.856      0.000      -0.244      -0.104\n",
       "x4            -0.2922      0.039     -7.474      0.000      -0.369      -0.216\n",
       "x5             0.9019      0.348      2.592      0.010       0.220       1.584\n",
       "x6             0.1081      0.035      3.076      0.002       0.039       0.177\n",
       "x7             0.2198      0.066      3.307      0.001       0.090       0.350\n",
       "x8            -0.0078      0.029     -0.270      0.787      -0.064       0.049\n",
       "x9             0.1279      0.306      0.418      0.676      -0.471       0.727\n",
       "x10            0.0384      0.034      1.125      0.261      -0.028       0.105\n",
       "x11            0.1980      0.056      3.518      0.000       0.088       0.308\n",
       "x12            0.0899      0.072      1.241      0.215      -0.052       0.232\n",
       "x13           -0.8298      0.043    -19.264      0.000      -0.914      -0.745\n",
       "x14           -0.6041      0.037    -16.135      0.000      -0.677      -0.531\n",
       "x15           -0.3942      0.037    -10.685      0.000      -0.467      -0.322\n",
       "x16           -0.1707      0.039     -4.374      0.000      -0.247      -0.094\n",
       "x17            0.0425      0.010      4.224      0.000       0.023       0.062\n",
       "x18           -0.0272      0.010     -2.599      0.009      -0.048      -0.007\n",
       "x19           -0.0182      0.013     -1.359      0.174      -0.045       0.008\n",
       "x20            0.0271      0.011      2.358      0.018       0.005       0.050\n",
       "x21            0.3334      0.107      3.123      0.002       0.124       0.543\n",
       "x22           -0.0434      0.032     -1.376      0.169      -0.105       0.018\n",
       "x23            0.0991      0.046      2.131      0.033       0.008       0.190\n",
       "x24           -0.0534      0.022     -2.386      0.017      -0.097      -0.010\n",
       "x25            0.2253      0.081      2.768      0.006       0.066       0.385\n",
       "x26            0.0191      0.022      0.875      0.381      -0.024       0.062\n",
       "x27            0.1011      0.035      2.902      0.004       0.033       0.169\n",
       "x28            0.0020      0.076      0.026      0.979      -0.146       0.150\n",
       "x29           -0.2560      0.066     -3.904      0.000      -0.385      -0.127\n",
       "x30           -0.2132      0.052     -4.082      0.000      -0.316      -0.111\n",
       "x31           -0.1933      0.049     -3.965      0.000      -0.289      -0.098\n",
       "x32           -0.0799      0.051     -1.576      0.115      -0.179       0.019\n",
       "x33            0.0423      0.004     11.059      0.000       0.035       0.050\n",
       "x34            0.0018      0.008      0.218      0.827      -0.015       0.018\n",
       "x35            0.0639      0.009      6.886      0.000       0.046       0.082\n",
       "x36           -0.0571      0.074     -0.772      0.440      -0.202       0.088\n",
       "x37           -0.0270      0.018     -1.495      0.135      -0.062       0.008\n",
       "x38            0.0135      0.034      0.400      0.689      -0.053       0.080\n",
       "x39           -0.0213      0.015     -1.463      0.143      -0.050       0.007\n",
       "x40            0.0190      0.051      0.370      0.711      -0.082       0.120\n",
       "x41            0.0260      0.016      1.661      0.097      -0.005       0.057\n",
       "x42           -0.0298      0.027     -1.091      0.275      -0.083       0.024\n",
       "x43            0.0010      0.039      0.026      0.979      -0.075       0.077\n",
       "x44            0.1556      0.039      3.989      0.000       0.079       0.232\n",
       "x45            0.1520      0.028      5.479      0.000       0.098       0.206\n",
       "x46            0.1373      0.025      5.502      0.000       0.088       0.186\n",
       "x47            0.0412      0.025      1.667      0.096      -0.007       0.090\n",
       "x48            0.0637      0.010      6.288      0.000       0.044       0.084\n",
       "x49            0.0427      0.010      4.271      0.000       0.023       0.062\n",
       "x50            0.0230      0.076      0.301      0.763      -0.127       0.173\n",
       "x51            0.0021      0.022      0.097      0.923      -0.041       0.045\n",
       "x52           -0.0766      0.037     -2.088      0.037      -0.148      -0.005\n",
       "x53            0.0680      0.018      3.806      0.000       0.033       0.103\n",
       "x54           -0.0135      0.098     -0.138      0.890      -0.205       0.178\n",
       "x55            0.0335      0.017      1.934      0.053      -0.000       0.068\n",
       "x56            0.0161      0.029      0.550      0.582      -0.041       0.073\n",
       "x57            0.0422      0.057      0.739      0.460      -0.070       0.154\n",
       "x58            0.2166      0.052      4.193      0.000       0.115       0.318\n",
       "x59            0.1980      0.038      5.237      0.000       0.124       0.272\n",
       "x60            0.1454      0.035      4.132      0.000       0.076       0.214\n",
       "x61            0.0770      0.037      2.086      0.037       0.005       0.149\n",
       "x62            0.0361      0.007      4.933      0.000       0.022       0.050\n",
       "x63           -0.1286      0.095     -1.347      0.178      -0.316       0.059\n",
       "x64           -0.0116      0.023     -0.502      0.616      -0.057       0.034\n",
       "x65            0.1940      0.039      4.939      0.000       0.117       0.271\n",
       "x66            0.0352      0.015      2.278      0.023       0.005       0.065\n",
       "x67           -0.0920      0.078     -1.174      0.240      -0.246       0.062\n",
       "x68           -0.0820      0.017     -4.869      0.000      -0.115      -0.049\n",
       "x69            0.0612      0.027      2.248      0.025       0.008       0.115\n",
       "x70            0.1649      0.068      2.441      0.015       0.032       0.297\n",
       "x71            0.2276      0.049      4.648      0.000       0.132       0.324\n",
       "x72            0.0238      0.041      0.586      0.558      -0.056       0.103\n",
       "x73            0.0397      0.039      1.023      0.306      -0.036       0.116\n",
       "x74            0.0147      0.041      0.361      0.718      -0.065       0.095\n",
       "x75            0.9019      0.348      2.592      0.010       0.220       1.584\n",
       "x76           -0.6408      0.616     -1.040      0.298      -1.849       0.567\n",
       "x77           -0.5734      0.172     -3.335      0.001      -0.910      -0.236\n",
       "x78           -0.3475      0.153     -2.276      0.023      -0.647      -0.048\n",
       "x79           -1.7472      0.924     -1.892      0.059      -3.557       0.063\n",
       "x80            0.0060      0.145      0.041      0.967      -0.278       0.290\n",
       "x81           -0.2569      0.199     -1.288      0.198      -0.648       0.134\n",
       "x82           -0.8789      0.214     -4.113      0.000      -1.298      -0.460\n",
       "x83            0.2415      0.407      0.594      0.553      -0.556       1.039\n",
       "x84            0.0584      0.260      0.225      0.822      -0.450       0.567\n",
       "x85            0.0673      0.208      0.324      0.746      -0.340       0.475\n",
       "x86           -0.1320      0.225     -0.585      0.558      -0.574       0.310\n",
       "x87            0.1081      0.035      3.076      0.002       0.039       0.177\n",
       "x88            0.0388      0.079      0.489      0.625      -0.117       0.194\n",
       "x89            0.0132      0.043      0.309      0.757      -0.071       0.097\n",
       "x90            0.1017      0.309      0.329      0.742      -0.505       0.708\n",
       "x91            0.0490      0.041      1.183      0.237      -0.032       0.130\n",
       "x92           -0.0031      0.063     -0.049      0.961      -0.126       0.120\n",
       "x93            0.0913      0.089      1.023      0.306      -0.084       0.266\n",
       "x94            0.1257      0.132      0.952      0.341      -0.133       0.385\n",
       "x95           -0.0403      0.082     -0.489      0.625      -0.202       0.121\n",
       "x96            0.0754      0.069      1.090      0.276      -0.060       0.211\n",
       "x97           -0.0559      0.067     -0.839      0.402      -0.186       0.075\n",
       "x98            0.2198      0.066      3.307      0.001       0.090       0.350\n",
       "x99            0.0036      0.068      0.053      0.958      -0.131       0.138\n",
       "x100          -0.9623      0.379     -2.536      0.011      -1.706      -0.219\n",
       "x101          -0.1348      0.076     -1.765      0.078      -0.284       0.015\n",
       "x102          -0.3318      0.129     -2.574      0.010      -0.584      -0.079\n",
       "x103          -0.0362      0.211     -0.172      0.864      -0.450       0.378\n",
       "x104          -0.1154      0.172     -0.673      0.501      -0.452       0.221\n",
       "x105          -0.1771      0.140     -1.263      0.207      -0.452       0.098\n",
       "x106          -0.0104      0.132     -0.079      0.937      -0.268       0.248\n",
       "x107          -0.0593      0.137     -0.434      0.664      -0.327       0.209\n",
       "x108          -0.0078      0.029     -0.270      0.787      -0.064       0.049\n",
       "x109           0.0695      0.137      0.508      0.611      -0.199       0.338\n",
       "x110           0.0129      0.030      0.431      0.667      -0.046       0.071\n",
       "x111          -0.0357      0.049     -0.734      0.463      -0.131       0.060\n",
       "x112           0.1452      0.091      1.595      0.111      -0.033       0.324\n",
       "x113           0.2281      0.082      2.794      0.005       0.068       0.388\n",
       "x114           0.1312      0.064      2.062      0.039       0.006       0.256\n",
       "x115           0.0770      0.058      1.323      0.186      -0.037       0.191\n",
       "x116           0.0500      0.060      0.839      0.401      -0.067       0.167\n",
       "x117           0.1279      0.306      0.418      0.676      -0.471       0.727\n",
       "x118       -5.964e-16      5e-16     -1.192      0.233   -1.58e-15    3.84e-16\n",
       "x119       -5.307e-16   3.08e-16     -1.720      0.085   -1.14e-15    7.39e-17\n",
       "x120       -1.768e-16   2.28e-16     -0.777      0.437   -6.23e-16    2.69e-16\n",
       "x121          -0.3760      0.640     -0.588      0.557      -1.630       0.878\n",
       "x122          -0.4990      0.618     -0.807      0.419      -1.710       0.712\n",
       "x123          -0.7557      0.627     -1.205      0.228      -1.985       0.474\n",
       "x124          -0.9930      0.763     -1.301      0.193      -2.489       0.503\n",
       "x125           0.0384      0.034      1.125      0.261      -0.028       0.105\n",
       "x126       -4.394e-17   1.16e-16     -0.377      0.706   -2.72e-16    1.84e-16\n",
       "x127           0.1371      0.116      1.184      0.236      -0.090       0.364\n",
       "x128           0.0037      0.086      0.043      0.966      -0.166       0.173\n",
       "x129          -0.0659      0.074     -0.890      0.374      -0.211       0.079\n",
       "x130          -0.0422      0.070     -0.603      0.547      -0.179       0.095\n",
       "x131           0.0812      0.075      1.080      0.280      -0.066       0.229\n",
       "x132           0.1980      0.056      3.518      0.000       0.088       0.308\n",
       "x133           0.0593      0.226      0.262      0.793      -0.384       0.503\n",
       "x134          -0.0794      0.139     -0.570      0.569      -0.353       0.194\n",
       "x135          -0.1359      0.121     -1.127      0.260      -0.372       0.100\n",
       "x136          -0.0516      0.114     -0.453      0.651      -0.275       0.172\n",
       "x137          -0.0998      0.125     -0.799      0.425      -0.345       0.145\n",
       "x138           0.0899      0.072      1.241      0.215      -0.052       0.232\n",
       "x139                0          0        nan        nan           0           0\n",
       "x140                0          0        nan        nan           0           0\n",
       "x141                0          0        nan        nan           0           0\n",
       "x142                0          0        nan        nan           0           0\n",
       "x143          -0.8298      0.043    -19.264      0.000      -0.914      -0.745\n",
       "x144                0          0        nan        nan           0           0\n",
       "x145                0          0        nan        nan           0           0\n",
       "x146                0          0        nan        nan           0           0\n",
       "x147          -0.6041      0.037    -16.135      0.000      -0.677      -0.531\n",
       "x148                0          0        nan        nan           0           0\n",
       "x149                0          0        nan        nan           0           0\n",
       "x150          -0.3942      0.037    -10.685      0.000      -0.467      -0.322\n",
       "x151                0          0        nan        nan           0           0\n",
       "x152          -0.1707      0.039     -4.374      0.000      -0.247      -0.094\n",
       "==============================================================================\n",
       "Omnibus:                       63.180   Durbin-Watson:                   2.017\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               83.302\n",
       "Skew:                          -0.044   Prob(JB):                     8.15e-19\n",
       "Kurtosis:                       3.340   Cond. No.                     1.29e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.71e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.OLS(y_train, sm.add_constant(X_poly_train)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:      0.6532701480220614\n",
      "Validation score: 0.6523981556506147\n",
      "X-test score: 0.6352544653210463\n",
      "R2 score: 0.6352544653210463\n",
      "Mean**2 Error 0.601024386635919\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:,'int4'] = X_train['sqft_living'] * X_train['yr_built']\n",
    "X_test.loc[:,'int4'] = X_test['sqft_living'] * X_test['yr_built']\n",
    "\n",
    "dp.scores(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.653</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.653</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1792.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 May 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:57:16</td>     <th>  Log-Likelihood:    </th> <td> -14432.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 16197</td>      <th>  AIC:               </th> <td>2.890e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 16179</td>      <th>  BIC:               </th> <td>2.904e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>    0.9193</td> <td>    0.025</td> <td>   37.368</td> <td> 0.000</td> <td>    0.871</td> <td>    0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living</th>         <td>    0.3313</td> <td>    0.008</td> <td>   40.086</td> <td> 0.000</td> <td>    0.315</td> <td>    0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>            <td>   -0.0679</td> <td>    0.006</td> <td>  -11.737</td> <td> 0.000</td> <td>   -0.079</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors</th>              <td>    0.0881</td> <td>    0.007</td> <td>   12.994</td> <td> 0.000</td> <td>    0.075</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>            <td>   -0.2792</td> <td>    0.006</td> <td>  -44.584</td> <td> 0.000</td> <td>   -0.292</td> <td>   -0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th>          <td>    0.9788</td> <td>    0.058</td> <td>   16.765</td> <td> 0.000</td> <td>    0.864</td> <td>    1.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view</th>                <td>    0.2604</td> <td>    0.017</td> <td>   15.076</td> <td> 0.000</td> <td>    0.227</td> <td>    0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_renovated</th>        <td>    0.1019</td> <td>    0.027</td> <td>    3.751</td> <td> 0.000</td> <td>    0.049</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_basement</th>        <td>    0.1355</td> <td>    0.012</td> <td>   11.473</td> <td> 0.000</td> <td>    0.112</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_Fair</th>      <td>   -0.3077</td> <td>    0.050</td> <td>   -6.190</td> <td> 0.000</td> <td>   -0.405</td> <td>   -0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_Good</th>      <td>    0.0484</td> <td>    0.012</td> <td>    4.110</td> <td> 0.000</td> <td>    0.025</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_Very Good</th> <td>    0.1957</td> <td>    0.019</td> <td>   10.442</td> <td> 0.000</td> <td>    0.159</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_11 Excellent</th>  <td>    0.5324</td> <td>    0.037</td> <td>   14.308</td> <td> 0.000</td> <td>    0.459</td> <td>    0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_6 Low Average</th> <td>   -1.8565</td> <td>    0.033</td> <td>  -56.955</td> <td> 0.000</td> <td>   -1.920</td> <td>   -1.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_7 Average</th>     <td>   -1.3468</td> <td>    0.026</td> <td>  -51.243</td> <td> 0.000</td> <td>   -1.398</td> <td>   -1.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_8 Good</th>        <td>   -0.8982</td> <td>    0.024</td> <td>  -36.872</td> <td> 0.000</td> <td>   -0.946</td> <td>   -0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade_9 Better</th>      <td>   -0.4014</td> <td>    0.025</td> <td>  -16.287</td> <td> 0.000</td> <td>   -0.450</td> <td>   -0.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>int4</th>                <td>    0.0449</td> <td>    0.005</td> <td>    8.519</td> <td> 0.000</td> <td>    0.035</td> <td>    0.055</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>48.702</td> <th>  Durbin-Watson:     </th> <td>   2.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  61.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.039</td> <th>  Prob(JB):          </th> <td>3.81e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.293</td> <th>  Cond. No.          </th> <td>    17.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.653\n",
       "Model:                            OLS   Adj. R-squared:                  0.653\n",
       "Method:                 Least Squares   F-statistic:                     1792.\n",
       "Date:                Sun, 08 May 2022   Prob (F-statistic):               0.00\n",
       "Time:                        11:57:16   Log-Likelihood:                -14432.\n",
       "No. Observations:               16197   AIC:                         2.890e+04\n",
       "Df Residuals:                   16179   BIC:                         2.904e+04\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                   0.9193      0.025     37.368      0.000       0.871       0.968\n",
       "sqft_living             0.3313      0.008     40.086      0.000       0.315       0.348\n",
       "sqft_lot               -0.0679      0.006    -11.737      0.000      -0.079      -0.057\n",
       "floors                  0.0881      0.007     12.994      0.000       0.075       0.101\n",
       "yr_built               -0.2792      0.006    -44.584      0.000      -0.292      -0.267\n",
       "waterfront              0.9788      0.058     16.765      0.000       0.864       1.093\n",
       "view                    0.2604      0.017     15.076      0.000       0.227       0.294\n",
       "is_renovated            0.1019      0.027      3.751      0.000       0.049       0.155\n",
       "has_basement            0.1355      0.012     11.473      0.000       0.112       0.159\n",
       "condition_Fair         -0.3077      0.050     -6.190      0.000      -0.405      -0.210\n",
       "condition_Good          0.0484      0.012      4.110      0.000       0.025       0.071\n",
       "condition_Very Good     0.1957      0.019     10.442      0.000       0.159       0.232\n",
       "grade_11 Excellent      0.5324      0.037     14.308      0.000       0.459       0.605\n",
       "grade_6 Low Average    -1.8565      0.033    -56.955      0.000      -1.920      -1.793\n",
       "grade_7 Average        -1.3468      0.026    -51.243      0.000      -1.398      -1.295\n",
       "grade_8 Good           -0.8982      0.024    -36.872      0.000      -0.946      -0.850\n",
       "grade_9 Better         -0.4014      0.025    -16.287      0.000      -0.450      -0.353\n",
       "int4                    0.0449      0.005      8.519      0.000       0.035       0.055\n",
       "==============================================================================\n",
       "Omnibus:                       48.702   Durbin-Watson:                   2.009\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               61.796\n",
       "Skew:                          -0.039   Prob(JB):                     3.81e-14\n",
       "Kurtosis:                       3.293   Cond. No.                         17.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small increase in validation score with small increase in condition number.\n",
    "# This would be the final model.\n",
    "sm.OLS(y_train, sm.add_constant(X_train)).fit().summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
